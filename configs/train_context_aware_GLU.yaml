model:
  model_name: ASRLLM
  file: models/model.py:ASRLLM
  llm_model_name: llama3.2-3B
  llm_model: meta-llama/Llama-3.2-3B
  llm_model_path: null
  llm_type: decoder_only
  llm_dim: 3072

  # Projector type
  projector: context-aware-glu
  context_size: 3  # Number of patches in context window

  hidden_dim: 2048

  # Feature front-end
  mel_size: 80      # Keep for compatibility
  n_mfcc: 40        # MFCC size
  normalize: false

  # Patched projector core settings 
  patch_length: 16
  patch_stride: 8

  # Pre-patch normalization and regularization
  mel_input_norm: true
  mel_dropout: 0.20

  modal: audio
  encoder_type: finetune

train:
  model_name: ASRLLM
  run_validation: true
  batch_size: 8
  batching_strategy: packing
  context_length: 384
  gradient_accumulation_steps: 8
  grad_clip: 1.0
  num_epochs: 15
  num_workers: 8
  total_steps: 11000
  validation_interval: 350
  lr: 2.0e-4  
  weight_decay: 0.05  
  gamma: 0.85
  seed: 42
  use_fp16: false
  mixed_precision: true
  val_batch_size: 8

  # Fine-tuning/Adapter/Quantization controls
  use_peft: false
  output_dir: output_llama3b_3ctx_mfcc_norm_50h/  
  freeze_layers: false
  num_freeze_layers: 0
  quantization: false
  one_gpu: true
  save_model: true
  use_fast_kernels: false
  freeze_llm: true
  freeze_encoder: true

scheduler:
  enabled: true
  type: cosine_with_warmup
  num_warmup_steps: 336  
  num_cycles: 0.5
  lr_end: 1.0e-7
  use_hf: true

early_stopping:
  enabled: true
  monitor: val/loss
  mode: min
  patience: 8  
  min_delta: 0.001

data:
  dataset: speech_dataset
  file: datamodules/datasets.py:get_speech_dataset
  train_data_path: data/train-clean-50.jsonl
  val_data_path: data/dev-clean.jsonl
  test_data_path: data/test-clean.jsonl
  train_split: train
  val_split: val
  test_split: test
  prompt: null
  data_path: null
  max_words: null
  max_mel: null
  fix_length_audio: -1
  inference_mode: false
  
  # MFCC feature settings
  input_type: mfcc  # MFCC input
  mel_size: 80      # Keep for compatibility
  n_mfcc: 40        # MFCC coefficients
  
  # Audio processing parameters (for librosa)
  sample_rate: 16000   
  n_fft: 400           
  hop_length: 160      
  win_length: 400      
  fmin: 0              
  fmax: 8000           
  
  normalize: false
  
  # Mel normalization settings
  mel_input_norm: false
  mel_stats_path: data/mel_stats/  
  mel_mean_file: mel_means_train_50h.npy  
  mel_std_file: mel_stds_train_50h.npy
  
  mfcc_input_norm: true
  mfcc_stats_path: data/mfcc_stats/
  mfcc_mean_file: mfcc_means_train_50h.npy  
  mfcc_std_file: mfcc_stds_train_50h.npy    
  clamp_epsilon: 1e-8
  verbose: true

log:
  use_wandb: true
  wandb_dir: ./wandb
  wandb_entity_name: ASRLLM
  wandb_project_name: ASRLLM_llama_3B_CA_GLU_50h
  wandb_exp_name: exp_3ctx_mfcc_norm_50h  
  log_dir: ./logs
  log_filename: train_3ctx_mfcc_norm_50h.log  # ‚Üê FIXED
  log_interval: 50
